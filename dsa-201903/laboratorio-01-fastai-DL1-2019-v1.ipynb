{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Laboratório 01 - fast.ai DL1 2019 Brasília\n",
    "\n",
    "\n",
    "### Introdução\n",
    "\n",
    "Bem vindos ao primeiro laboratório da turma fast.ai DL1 2019. O objetivo do laboratório é consolidar os conhecimentos obtidos nas aulas 01 e 02, bem como promover debate, discussões relacionadas ao tema, bem como fazer com que a maioria coloque a \"mão na massa\" como gosta nosso guru, Jeremy.\n",
    "\n",
    "Realizaremos nesse laboratório o treinamento de uma rede neural para classificação de expressões faciais baseadas em fotos de pessoas. Utilizaremos a base de dados de um desafio do Kaggle de 2013, conforme detalhes mais adiante. O modelo treinado terá alcançado uma acurácia similiar, ou até superior, aos melhores modelos da competição em 2013. Além disso, vamos desenvolver um aplicativo web simples para colocar em produção nosso modelo treinado de a nos permitir testar novas imagens com expressões a avaliar a acurácia da rede neural na prática.\n",
    "\n",
    "Esse notebook é uma combinação de dois posts do colega [Pierre Guillou](https://www.linkedin.com/in/pierreguillou/), que cedeu seu código para que possamos consolidar nossos conhecimentos:\n",
    "\n",
    "- [Face Expression Recognition with fastai v1](https://medium.com/@pierre_guillou/face-expression-recognition-with-fastai-v1-dc4cf6b141a3).\n",
    "- [Deep Learning Web App by fastai v1](https://medium.com/@pierre_guillou/deep-learning-web-app-by-fastai-v1-3ab4c20b7cac)\n",
    "\n",
    "\n",
    "### Reconhecimento de Expressões Faciais (Face Expression Recognition Kaggle Challenge - FER 2013) com fastai v1\n",
    "\n",
    "by: [Pierre Guillou](https://www.linkedin.com/in/pierreguillou/) (novembro 2018)  \n",
    "    [Leon Silva](https://www.linkedin.com/in/leonsolon/) (tradução/atualização março 2019)\n",
    "    [Vinícius Ramos](https://www.linkedin.com/in/vinicius-ramos-6a367073/) (atualização/deploy no Django na GCP março 2018)\n",
    "\n",
    "- Inspirado por [Recognizing Facial Expressions Using Deep Learning](http://cs231n.stanford.edu/reports/2017/pdfs/224.pdf) (2017) of Alexandru Savoiu and James Wong (Stanford University)\n",
    "- Base de dados : [FER 2013 Kaggle Challenge](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/)\n",
    "- Deep Learning utilizando [fastai v1](https://www.fast.ai/2018/10/02/fastai-ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização\n",
    "\n",
    "Vamos começar como todo e qualquer notebook que utiliza fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração da API Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faremos o download do banco de imagens diretamente do Kaggle. Para tal, é necessário seguir os passos abaixo. Este notebook está focalizado na google cloud platform (GCP), tendo em vista que a maioria da turma realizou essa instalação. Se você está lendo isso é porque já está rodando o jupyter de alguma forma, seja na máquina local, seja no gcp, portanto, pularemos os passos de inicialização da instância e do jupyter.\n",
    "\n",
    "1. Caso ainda não possua, cria sua conta no [Kaggle](https://www.kaggle.com) no seu computador local\n",
    "2. No canto superior direito, clique na sua foto (ou avatar) e selecione 'My account'\n",
    "3. Selecione a opção 'Create API Token'. \n",
    "4. Ao selecionar a opção será baixado um arquivo na sua máquina, chamada `kaggle.json`. Esse arquivo contém as credenciais da API do Kaggle (nome de usuário e senha)\n",
    "5. Abra o arquivo `kaggle.json` no seu editor de textos preferido e copie o conteúdo. Cole o conteúdo na célula abaixo, no local indicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando que cria a pasta Kaggle em /home/<seu_usuario>. Essa pasta é necessária para conter a chave de API do Kaggle\n",
    "!rm -rf ~/.kaggle\n",
    "!mkdir ~/.kaggle\n",
    "\n",
    "# Esse comando cria o arquivo kaggle.json na instância no local correto: /home/<seu_usuario/.kaggle/kaggle.json\n",
    "!echo 'conteudo do kaggle.json' >> ~/.kaggle/kaggle.json\n",
    "\n",
    "# Por questões de segurança, garanta que outros usuários do seu computador não tenham acesso de leitura \n",
    "# às suas credenciais. Esse comando é necessário, do contrário a API do Kaggle se recusa a fazer o download das bases de dados.\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com a chave de API do Kaggle, agora é a vez de instalar a API do kaggle\n",
    "!sudo pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Termos da competição\n",
    "\n",
    "Um passo importante, antes de baixar os dados do Kaggle, é aceitar os termos da competição. Para isso, acesse a seção `rules` na [página da competição](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/rules) e clique em `I Understand and Accept`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download do Kaggle\n",
    "\n",
    "Agora que temos a conta, chave de API e pacote instalado, basta realizarmos o download das imagens com as expressões faciais direto do kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para alterar pasta para '~/.fastai/data', onde os arquivos serão armazenados. \n",
    "%cd ~/.fastai/data/\n",
    "\n",
    "# Finnalmente, download do arquivo FER 2013 a partir da conta do Kaggle (fer2013.tar.gz)\n",
    "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use os comandos abaixo para criar uma pasta para FER (face expression recognition)\n",
    "# e para descompactar o arquivo dentro da pasta FER\n",
    "!mkdir FER\n",
    "!mv fer2013.tar.gz FER\n",
    "!rm example_submission.csv\n",
    "!tar -xvf FER/fer2013.tar.gz -C FER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listando arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se os arquivos foram decompactados corretamente\n",
    "%cd ~/.fastai/data/\n",
    "PATH = Path('./FER/fer2013')\n",
    "PATH.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessa competição, as imagens foram armazenadas em forma de pixels, com os valores RGB de cada\n",
    "# A 1a coluna apresenta a emoção (expressão) a qual a imagem representa\n",
    "# A 2a coluna apresenta a imagem em si, num arranjo de números RFB que representa os pixels\n",
    "# A 3a coluna traz a utilidade da imagem, se será utilizada para treinamento, teste público ou teste privado (detalhes mais adiante).\n",
    "df = pd.read_csv(PATH/'fer2013.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As expressões das imagens na descrição do desafio do Kaggle, de 0 a 6 são\n",
    "# Raiva, Nojo, Medo, Alegria, Tristeza, Surpresa, Neutro\n",
    "labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "for l in range(len(labels)):\n",
    "    print(f'{l} = {labels[l]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também temos a utilização das imagens, treinamento, teste público e teste privado \n",
    "# Os desafios Kaggle possuem um teste público, com a base que disponibilizam para criação dos modelos\n",
    "# e uma privada que somente é testada com a submissão dos resultados\n",
    "usages = df['Usage'].unique();usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos separar os data frames em treinamento, teste público e teste privado\n",
    "df_train = df[df['Usage'] == 'Training']\n",
    "df_valid = df[df['Usage'] == 'PublicTest']\n",
    "df_test = df[df['Usage'] == 'PrivateTest']\n",
    "\n",
    "# Os tamanhos de cada data frame\n",
    "n_train = len(df_train)\n",
    "n_valid = len(df_valid)\n",
    "n_test = len(df_test)\n",
    "n = len(df)\n",
    "\n",
    "print(f'{n_train} (Training) + {n_valid} (PublicTest) + {n_test} (PrivateTest) = {n} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograma das bases de treinamento, teste público e teste privado\n",
    "def setup_axe(axe,df,title):\n",
    "    axe.hist(df['emotion'])\n",
    "    axe.set_xticks(list(range(len(labels))))\n",
    "    axe.set_xticklabels(labels, rotation=45)\n",
    "    axe.set_title(title)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(15,5))\n",
    "setup_axe(axes[0],df_train,'treinamento')\n",
    "setup_axe(axes[1],df_valid,'validação')\n",
    "setup_axe(axes[2],df_test,'teste')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos avaliar a proporção das imagens na base de treinamento de cada uma das 7 expressões\n",
    "ne = df_train['emotion'].value_counts(ascending=True)\n",
    "for k,v in zip(ne.keys(),ne.values):\n",
    "    pct = round(v/n*100,2)\n",
    "    print(f'({pct}%) {v} {labels[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função abaixo recria a imagem a partir dos pixels. Lembrando que as imagens são sequências de 3 números para cada pixel, ex (48,48,3)\n",
    "# Vamos representar a expressão como um inteiro e os pixels de uma imagem como um array numpy \n",
    "def row2image(row):\n",
    "    pixels, emotion = row['pixels'], row['emotion']\n",
    "    img = np.array(pixels.split())\n",
    "    img = img.reshape(48,48)\n",
    "    image = np.zeros((48,48,3))\n",
    "    image[:,:,0] = img\n",
    "    image[:,:,1] = img\n",
    "    image[:,:,2] = img\n",
    "    return np.array([image.astype(np.uint8), emotion])\n",
    "\n",
    "# Apresenta imagem já convertida com o título da expressão\n",
    "def show(img_title):\n",
    "    plt.imshow(img_title[0])\n",
    "    plt.title(labels[img_title[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dar uma olhada na base para ver as imagens? Brinquem à vontade, aqui não somos Gilberto Gil, mas vamos de 2222\n",
    "row = df_train.iloc[2222]\n",
    "img = row2image(row)\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armazenar os dados (pixels) em forma de imagens nas pastas train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com a função de pixels (com 3 números cada) para arquivos, vamos agora criar as pastas para armazenar cria as pastas train, valid e test\n",
    "Path(PATH/'train').mkdir(exist_ok=True)\n",
    "Path(PATH/'valid').mkdir(exist_ok=True)\n",
    "Path(PATH/'test').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as variáveis das pastas de treinamento, teste público e teste privado\n",
    "PATH_train = PATH/'train'\n",
    "PATH_valid = PATH/'valid'\n",
    "PATH_test = PATH/'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria as 7 pastas das expressões em cada uma das pastas train, train, val e test\n",
    "for l in labels:\n",
    "    Path(PATH_train/l).mkdir(exist_ok=True)\n",
    "    Path(PATH_valid/l).mkdir(exist_ok=True)\n",
    "    Path(PATH_test/l).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria as imagens a partir dos pixels e salva nas subpastas correspondentes. Aqui utilizaremos o teste público como validação\n",
    "# e teste privado como teste\n",
    "def createImages(df,path):\n",
    "    for e in range(len(labels)):\n",
    "        df_e = df[df['emotion'] == e]\n",
    "        path_e = path/labels[e]\n",
    "        i=0\n",
    "        for index, row in df_e.iterrows():\n",
    "            img = row2image(row)\n",
    "            image = PIL.Image.fromarray(img[0], 'RGB')\n",
    "            fname = str(e)+'_'+str(i)+'.jpg'\n",
    "            image.save(path_e/fname)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria as imagens e posiciona nas subpastas\n",
    "createImages(df_train,PATH_train)\n",
    "createImages(df_valid,PATH_valid)\n",
    "createImages(df_test,PATH_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos dar uma olhada se a criação ocorreu da forma desejada\n",
    "p = PATH_train/'Angry'\n",
    "p.ls()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar o ImageDataBunch parametrizado para resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria transformações para as imagens como forma de aumentar as informações do dataset (data augmentation)\n",
    "tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataBunch\n",
    "# bs=16, size=299 : ajustamos os parametros para o laboratório terminar num tempo razoável, mas o melhor seria o valor \n",
    "# do hiperparâmetro size=299 para ajudar à resnet50\n",
    "data = ImageDataBunch.from_folder(PATH, ds_tfms=tfms, bs=16, size=224)\n",
    "data.normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes, data.c, len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar o modelo com transfer learning (resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o learner a partir do resnet50 com métrica de acurácia para buscar dos coeficientes da rede neural\n",
    "learn = cnn_learner(data, models.resnet50, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one cycle training com 4 épocas\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando o estágio atual (caso o preemptive resolve nos ajudar O.o)\n",
    "learn.save('fer2013-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fer2013-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com o modelo treinado somente com as novas imagens, vamos \"descongelar\" o learner para reaprender com o resnet50 completo\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buscar os melhores learning rates\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# com base no gráfico vamos retreinar com 6 épocas e learning rates específicos\n",
    "learn.fit_one_cycle(6, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvar estágio atual\n",
    "learn.save('fer2013-stage-2')\n",
    "\n",
    "# exportar o modelo treinado. Importante para implantarmos no nosso aplicativo web!\n",
    "learn.export('modelo.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "\n",
    "Com o modelo treinado, vamos avaliar os resultados, principalmente com relação a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fer2013-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A matriz de confusão mostra que, para as expressões com mais dados para treinamento temos um acerto maior\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliando quais foram as piores classificações em termos de erro\n",
    "interp.plot_top_losses(9, figsize=(15,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probs, val_targets = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.argmax(val_probs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = (val_preds == val_targets).type(torch.FloatTensor).mean().item()\n",
    "print(f'valid accuracy: {round(val_acc*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de parecer pouco, um modelo com 64% de acurácia estaria bem colocado no desafio do Kaggle, isso sem muito esforço, pois poderíamos melhorar o tamanho da imagem e realizar limpeza das imagens expúreas/dúbias.\n",
    "\n",
    "\n",
    "# Utilizando o modelo em produção (predição de novas fotos)\n",
    "\n",
    "Agora vamos testar nosso modelo com aquelas imagens que não foram utilizadas nem no treino nem na validação. Brinquem à vontade, alterando a pasta de 'Happy' para outras expressões, bem como o índice do array de arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image from test folder (images arquived in subfolders)\n",
    "p = PATH_test/'Happy'\n",
    "url = p.ls()[1]\n",
    "img = open_image(url)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction\n",
    "#probs = learn.predict(img)\n",
    "#prediction = learn.data.classes[probs.argmax()]\n",
    "#prediction\n",
    "\n",
    "pred_class,pred_idx,outputs = learn.predict(img)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando imagem da internet\n",
    "\n",
    "Vamos tentar buscar uma imagem na internet e realizar uma classificação da expressão facial? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download da imagem\n",
    "!wget http://thesharpe.com/wp-content/uploads/2017/01/surprise-someone-1-1024x768.jpg\n",
    "    \n",
    "# Transformação para grayscale (as imagens treinadas e validadas também estão em grayscale)\n",
    "img = PIL.Image.open('surprise-someone-1-1024x768.jpg').convert('LA')\n",
    "\n",
    "# Salvar a imagem (percebam que o formato deve ser png)\n",
    "img.save('surprise-someone-1-1024x768.png')    \n",
    "    \n",
    "# Mudança de semântica! Antes img era uma imagem do pacote PIL, agora é uma imagem fast.ai (open_image)    \n",
    "img = open_image('./surprise-someone-1-1024x768.png')\n",
    "\n",
    "# Vamos dar uma olhada na imagem baixada em grayscale\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos realizar as transformações utilizadas nas imagens de treino? A imagem a ser classificada será reduzida e poderá\n",
    "# sofrer algumas rotações e distorções\n",
    "tfms = get_transforms()\n",
    "\n",
    "for transformation in tfms:\n",
    "    img = img.apply_tfms(transformation, size=224)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, vamos prever o que o Kevin McCallister estava expressando\n",
    "pred_class,pred_idx,outputs = learn.predict(img)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como disponibilizar seu modelo na internet\n",
    "\n",
    "Agora que temos um modelo treinado, funcionando razoavelmente bem, que tal criarmos uma aplicação web que recebe fotos e classifica a expressão do rosto?\n",
    "\n",
    "O colega Vinícius Ramos subiu no github uma [aplicação](https://github.com/viniciusramos91/ai-web-app.git) pronta para realizarmos o deploy do modelo treinado na própria instância do GCP: uma mão na roda :)\n",
    "\n",
    "Vamos aproveitar a aplicação aqui para utilizar o nosso modelo exportado. Devemos clonar o projeto para buscar os arquivos necessários para nossa web app.\n",
    "\n",
    "Para tal, utilizaremos o Django, um _framework_ web robusto escrito em Python, para fazer o _deploy_ do seu modelo. Dessa forma, qualquer um poderá acessar sua aplicação e testá-la."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um pouco sobre Django..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Django é um framework de alto nível, escrito em Python que encoraja o desenvolvimento limpo de aplicações web.\n",
    "\n",
    "Desenvolvido por experientes desenvolvedores, Django toma conta da parte pesada do desenvolvimento web, como: \n",
    "- Tratamento de requisições\n",
    "- Mapeamento objeto-relacional\n",
    "- Preparação de respostas HTTP\n",
    "- Autenticação\n",
    "- Autorização; e muito mais\n",
    "\n",
    "Dessa forma, você gasta seu esforço com aquilo que realmente interessa: suas **regras de negócio**!\n",
    "\n",
    "Foi desenvolvido com uma preocupação extra em segurança, evitando os mais comuns ataques, como _Cross Site Scripting_ (XSS), _Cross Site Request Forgery_ (CSRF), _SQL injection_, entre outros.\n",
    "\n",
    "É bastante **escalável**: Django foi desenvolvido para tirar vantagem da maior quantidade de hardware possível (desde que você queira). Django usa uma arquitetura “zero-compartilhamento”, o que significa que você pode adicionar mais recursos em qualquer nível: servidores de banco de dados, cache e/ou servidores de aplicação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sua arquitetura\n",
    "\n",
    "Diferente da arquitetura de outros _frameworks_ web que seguem o padrão MVC (_Model-View-Controller_), o Django possui uma arquitetura sutilmente diferente: seus desenvolvedores o denominaram de **MTV** ou _**Model-Template-View**_.\n",
    "\n",
    "As responsabilidades de cada camada são:\n",
    "- _**Model**_: Faz o mapeamento dos objetos da sua aplicação com tabelas relacionais e gerencia as transações que acessam o banco de dados.\n",
    "- _**Template**_: Contém a camada de apresentação da sua aplicação (arquivos HTML, arquivos de estilo CSS, possíveis bibliotecas Javascript e etc). É a **cara** do seu projeto.\n",
    "- _**View**_: Essa camada tem a responsabilidade de processar as requisições vindas dos usuários, formular uma resposta e enviá-la. É aqui que residem nossas **lógicas de negócio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluxo de uma requisição\n",
    "\n",
    "O fluxo de uma Requisição HTTP dentro do Django pode ser demonstrado da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fluxo de uma requisição](https://raw.githubusercontent.com/viniciusramos91/ai-web-app/master/notebook/django-architecture.png)\n",
    "_Fonte: [Python Academy](https://pythonacademy.com.br/blog/desenvolvimento-web-com-python-e-django-introducao)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você já sabe (quase) tudo sobre o Django, vamos para a **prática**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiros passos\n",
    "\n",
    "Se você estiver utilizando a Google Cloud Platform, abra uma nova janela de terminal (_Open in browser window_):\n",
    "\n",
    "![Google Cloud Platform](https://raw.githubusercontent.com/viniciusramos91/ai-web-app/master/notebook/gcp.png)\n",
    "\n",
    "Agora, clone o projeto Django:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esses passos podem ser executados no próprio notebook ou no terminal SSH\n",
    "# Vá para pasta home\n",
    "%cd ~\n",
    "\n",
    "# Clone o projeto\n",
    "!git clone https://github.com/viniciusramos91/ai-web-app.git\n",
    "    \n",
    "# Vá para dentro do projeto\n",
    "%cd ./ai-web-app\n",
    "\n",
    "# Copei o modelo treinado para a pasta correta\n",
    "%mkdir /home/jupyter/playground\n",
    "%cp ~/.fastai/data/FER/fer2013/modelo.pkl /home/jupyter/playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, instale as dependências do projeto (no caso apenas o Django), executando a célula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estrutura do projeto é:\n",
    "\n",
    "```\n",
    "requirements.txt\n",
    "manage.py\n",
    "webapp/\n",
    "    > settings.py\n",
    "    > urls.py\n",
    "    > wsgi.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicando cada arquivo:\n",
    "\n",
    "- `requirements.txt`: Arquivo de dependências de projetos Python.\n",
    "- `manage.py`: Arquivo gerado automaticamente pelo Django que expõe comandos importantes para manutenção da nossa aplicação.\n",
    "- `webapp/settings.py`: Arquivo muito importante com as configurações do nosso projeto, como configurações do banco de dados, aplicativos instalados, configuração de arquivos estáticos e muito mais.\n",
    "- `webapp/urls.py`: Nossa URLConf - aqui vamos dizer ao Django quem responde a qual URL.\n",
    "- `webapp/wsgi.py``: Aqui configuramos a interface entre o servidor de aplicação e nossa aplicação Django.\n",
    "\n",
    "Com a estrutura acima criada, é necessário fazer a carga inicial do banco de dados do Django. \n",
    "\n",
    "Para isso, executaremos o comando `migrate` do Django conforme a célula abaixo (deverá ser criado o banco de dados `db.sqlite3` na raíz do projeto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python manage.py migrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, execute o comando abaixo e abra seu browser e acesse sua instância na porta 8000 com seu IP externo. \n",
    "\n",
    "Para **parar** sua execução, clique no botão de _Stop_ (barra de ferramentas do Jupyter - ao lado do _Run_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python manage.py runserver 0.0.0.0:8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tela inicial do projeto deverá ser mostrada:\n",
    "\n",
    "![Django default](https://raw.githubusercontent.com/viniciusramos91/ai-web-app/master/notebook/index.png)\n",
    "\n",
    "E ao fazer o upload de uma imagem, a seguinte tela será exibida:\n",
    "\n",
    "![Resultado](https://raw.githubusercontent.com/viniciusramos91/ai-web-app/master/notebook/result.png)\n",
    "\n",
    "**Obs**: Ainda não estárá funcionando pois seu modelo não foi configurado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendendo um pouco do projeto Django\n",
    "\n",
    "Com o objetivo de criar uma página gerenciada pelo Django, é necessário fazermos, basicamente, três passos:\n",
    "- Criar a página html que será mostrada ao usuário.\n",
    "- Escrever a lógica no arquivo `views.py` (ainda não criado).\n",
    "- Adicionar a rota no arquivo `urls.py` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivo `index.html`\n",
    "\n",
    "O arquivo `webapp/templates/webapp/index.html` contém o código HTML da nossa página inicial. \n",
    "\n",
    "Ela é responsável por fazer o _upload_ de uma foto ao Django.\n",
    "\n",
    "Sem muito mistério aqui..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivo `views.py`\n",
    "\n",
    "No Django, o código responsável por processar a requisição do usuário e retornar uma resposta reside em uma `View`.\n",
    "\n",
    "No nosso caso, nossa `View`:\n",
    "- Recebe uma imagem\n",
    "- Trata a imagem\n",
    "- Carrega nosso modelo\n",
    "- Faz o `predict` utilizando a imagem tratada\n",
    "- Retorna a classe daquela imagem\n",
    "\n",
    "Para que seu modelo seja executado, altere o arquivo `webapp/views.py`, onde se encontra o seguinte trecho de código:\n",
    "\n",
    "```python\n",
    "learn = load_learner('/home/jupyter/playground', fname='modelo.pkl')\n",
    "```\n",
    "\n",
    "_(Aponte para o arquivo do seu modelo)_\n",
    "\n",
    "O código da nossa `View` é o seguinte (siga os comentários):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from django.shortcuts import render\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from django.http import HttpRequest, HttpResponse\n",
    "from io import BytesIO\n",
    "\n",
    "# View da página principal\n",
    "# =======================================================================\n",
    "\n",
    "def index(request: HttpRequest) -> HttpResponse:\n",
    "\n",
    "    # Verifica o método HTTP\n",
    "    if request.method == 'GET':\n",
    "        # Se GET, renderiza a página HTML\n",
    "        return render(request, 'webapp/index.html', status=200)\n",
    "    \n",
    "    # Se POST\n",
    "    elif request.method == 'POST':\n",
    "        # Pega a image da requisição\n",
    "        image = request.FILES['image']\n",
    "\n",
    "        # Lê os bytes da imagem\n",
    "        data = BytesIO(image.read())\n",
    "\n",
    "        # Chama o PIL para converter a imagem em preto e branco\n",
    "        img = PIL.Image.open(data).convert('LA')\n",
    "\n",
    "        # Salva a imagem em disco\n",
    "        img.save('imagem.png')\n",
    "\n",
    "        # Abre a imagem com o fast.ai\n",
    "        img = open_image('imagem.png')\n",
    "\n",
    "        # Carrega o conjunto padrão de transformações do fast.ai para aplicar na imagem\n",
    "        tfms = get_transforms()\n",
    "\n",
    "        # Aplica as transofmrações na imagem\n",
    "        for transformation in tfms:\n",
    "            fastai_img = img.apply_tfms(transformation, size=224)\n",
    "\n",
    "        # Carrega o modelo\n",
    "        learn = load_learner('/home/jupyter/playground', fname='modelo.pkl')\n",
    "\n",
    "        # Executa o modelo sobre a imagem\n",
    "        pred_class, pred_idx, outputs = learn.predict(fastai_img)\n",
    "\n",
    "        return HttpResponse(pred_class, status=200)\n",
    "\n",
    "    else:\n",
    "        return HttpResponse('Método não permitido', status=405)\n",
    "```     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivo `urls.py`\n",
    "\n",
    "Para que o Django chame nossa `View` é necessário que sua rota esteja configurada corretamente.\n",
    "\n",
    "Isso é feito no arquivo `webapp/urls.py`. Veja como é simples (siga os comentários):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from django.contrib import admin\n",
    "from django.urls import path\n",
    "from webapp.views import index\n",
    "\n",
    "# Lista contendo todos os caminhos da sua aplicação\n",
    "urlpatterns = [\n",
    "    # Sim, o Django já vem com uma área de administrador por padrão!\n",
    "    # Acesse: https://docs.djangoproject.com/en/2.0/intro/tutorial02/#introducing-the-django-admin\n",
    "    path('admin/', admin.site.urls),\n",
    "    \n",
    "    # Rota que encaminha as requisições do caminho raíz para nossa view index()\n",
    "    path('', index)\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
